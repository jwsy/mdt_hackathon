# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  file {
    path => "D:/ELK-IR/veronica-pfirewall-06-14-20.csv"
    start_position => "beginning"
    exit_after_read => "true"
    mode => "read"
  }
}
filter {
  csv  {
    separator => ","
    columns => ["dstip","tcpflags","tcpack","Computer_Name","dstport","path","icmpcode","tcpwin","tcpsyn","info","protocol","icmptype","action","date_time","size","srcport","Domain_Name","srcip"]
  }
  date  {
    match => ["date_time","yyy-MM-dd HH:mm:ss","ISO8601"]
    timezone => "America/New_York"
    remove_field => ["date_time"]
  }
  geoip {
    source => "dstip"
    target => "dstip_geoip"
  }
  geoip  {
    source => "srcip"
    target => "srcip_geoip"
  }
}
output {
  elasticsearch {
    hosts => ["https://b8ea29634ec249f59e8905a7d7400368.eastus2.azure.elastic-cloud.com:9243"]
    index => "windowsfw-test-1-%{+YYYY.MM.dd}"
    user => "elastic"
    password => "XU53j7hO9RNKDEi6ISGDNFGH"
  }
stdout  {}
}
